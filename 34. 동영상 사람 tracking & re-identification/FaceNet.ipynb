{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FaceNet\n",
    "(2015년에 구글에서 공개한 모델로, 이미지 픽셀을 인풋으로 하는 CNN 을 사용) \n",
    "\n",
    "\n",
    "--- \n",
    "Directly Learns a mapping from face images to a compact Euclidean space. \n",
    "    * Distance: correspond to measure of face similarity \n",
    "\n",
    "즉, 인풋으로 받은 얼굴을 유클리드공간에 맵핑시킨다. 이미지 사이의 거리는 유사도를 나타낸다. 거리가 0.0이라면 같은 얼굴, 4.0이라면 반대 얼굴 \n",
    "\n",
    "    - 일단 맵핑을 하게되면 FaceNet embedding을 feature vector 로 사용해서  Face recognition, verfication, clustering을 간단히 할 수 있다. \n",
    "\n",
    "\n",
    "\n",
    "- Loss Function: 'triplet loss'. positive 예시로부터의 거리는 최소화하고, negative 예시로부터의 거리를 최대화시키는 loss function\n",
    "\n",
    "<img src=\"images/lossfunction.png\",width=400,height=200>\n",
    "\n",
    "- Embedding: 논문의 가장 중요한 부분중에 하나. 얼굴을 128차원으로 embedding 시킨다. Input feature (사람의 얼굴) -> vector "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예시: \n",
    "- https://github.com/ColeMurray/medium-facenet-tutorial\n",
    "- https://medium.com/@vinayakvarrier/building-a-real-time-face-recognition-system-using-pre-trained-facenet-model-f1a277a06947\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "L2 거리의 제곱이 얼굴의 유사도에 해당되도록 트레이닝을 시킨다. \n",
    "\n",
    "일단 임베팅을 하고 나면 다양한 작업들을 할 수 있다. \n",
    "- Face Verification: 같은 사람이라고 판단할 두 임베딩 사이 거리의 Threshold를 설정해서 단순하게 거리 구하기 \n",
    "\n",
    "- Recognition: 단순한 k-NN classification 문제가 된다. \n",
    "\n",
    "- Clustering: 단순한 k-means, agglomerative clustering 문제가 된다 \n",
    "\n",
    "---\n",
    " \n",
    "Input:\n",
    "    - 타겟 인물의 얼굴을 crop 한 사진\n",
    "    - 타겟 인물의 다른 사진 (얼굴만 crop) - Positive 예시\n",
    "    - 다른 사람의 사진 (얼굴만 crop) - Negative 예시\n",
    "\n",
    "Positive 예시로부터 거리를 최소화시키고, \n",
    "Negative 에시로부터의 거리를 최대화시킨다 \n",
    "\n",
    "<img src=\"images/facenet.png\",width=400,height=200>\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## 모델 Architecture: \n",
    "\n",
    "- Inception model & Zeiler&Fergus model 을 기반으로 했음 \n",
    "\n",
    "목표 output: embedding f(x) from image x into a feature space Rd\n",
    "\n",
    "\n",
    "    * Training data: mini-batch별로 한 인물의 얼굴을 약 40장 정도 확보함. Negative 예시는 랜덤하게 각 mini-batch에 포함시킴 \n",
    "    * 모델이 빨리 수렴하기 위해서는 Triplet 을 잘 고르는것이 중요하다. 하지만 직접 사람이 고르는건 한계가 있음 \n",
    "    \n",
    "    \n",
    "    \n",
    "- Stochastic Gradient Descent 이용 \n",
    "- Standard Backprop\n",
    "- AdaGrad 사용 \n",
    "- learning rate: 0.05 에서 시작해서 모델 마무리할때 남춤 \n",
    "- CPU 에서 1000~2000시간 트레이닝 (500시간이 지났을 때 loss가 크게 낮아짐) \n",
    "- margin alpha = 0.2\n",
    "\n",
    "\n",
    "--- \n",
    "\n",
    "### 2개의 NN 모델을 써서 비교했음 \n",
    "\n",
    "공통점: 두 모델 다 ReLU 사용 \n",
    "인풋 사이즈: 96x96 ~ 224x224 pixels\n",
    "\n",
    "A. Zeiler & Fergus 모델을 기반으로 한 모델 \n",
    "\n",
    "<img src=\"Desktop/ZFmodel.png\",width=400,height=1200>\n",
    "\n",
    "    - input/output: rows x cols x #filters \n",
    "    - kernel: rows x cols, stride\n",
    "    - maxout pooling size-> p=2\n",
    "\n",
    "\n",
    "B. Inception 을 기반으로 한 모델 \n",
    "\n",
    "\n",
    "<img src=\"Desktop/incep.png\",width=800,height=450>\n",
    "\n",
    "    - 약 6.6~7.5M parameter 적음 \n",
    "    - 조금 변형해서 parameter 의 개수를 줄이면 모바일에도 돌아갈 수 있음 \n",
    "    \n",
    "\n",
    "\n",
    "---\n",
    "---\n",
    "\n",
    "### 결과 \n",
    "<img src=\"Desktop/roc.png\",width=400,height=200>\n",
    "<img src=\"Desktop/result.png\",width=400,height=200>\n",
    "\n",
    "\n",
    "NN2, NN3, NN4, NNS1, NNS2: Inception 을 기반으로 한 모델들 \n",
    "    - Paramter 의 개수가 다르다: 정확도와 무게의 tradeoff "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source Github: https://github.com/davidsandberg/facenet/blob/master/src/facenet.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
